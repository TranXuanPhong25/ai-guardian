# AI Guardian - Secure AI Conversation Platform

![AI Guardian](https://img.shields.io/badge/AI%20Guardian-Secure%20Conversations-blue)
![Python](https://img.shields.io/badge/Python-3.11+-blue.svg)
![Next.js](https://img.shields.io/badge/Next.js-15.4.6-black)
![FastAPI](https://img.shields.io/badge/FastAPI-0.112.1-green)
![Docker](https://img.shields.io/badge/Docker-Compose-blue)

## ğŸ›¡ï¸ Overview

AI Guardian is a privacy-first conversational AI platform that automatically detects and masks sensitive information (PII) while providing intelligent document-based question answering through Retrieval-Augmented Generation (RAG). The platform ensures secure conversations by protecting personal data while maintaining the quality of AI interactions.

## âœ¨ Key Features

### ğŸ”’ Privacy & Security
- **Automatic PII Detection**: Real-time detection of sensitive information using Presidio
- **Data Masking**: Intelligent pseudonymization of personal data
- **Secure File Upload**: Protected file storage with MinIO
- **Session Management**: Secure user authentication and session handling

### ğŸ¤– AI Capabilities
- **RAG-Powered Q&A**: Document-based question answering with Weaviate vector database
- **Multi-LLM Support**: Integration with Azure OpenAI and Google Gemini
- **File Processing**: Extract text from PDF, DOCX, images, and other formats
- **Smart Agent System**: Intelligent routing between conversation and RAG agents

### ğŸ“ File Management
- **Multiple Format Support**: PDF, DOCX, TXT, CSV, Excel, images (PNG, JPG, JPEG)
- **Document Ingestion**: Automatic processing and vectorization of uploaded documents
- **Text Extraction**: Advanced OCR and document parsing using SmolDocling

### ğŸ’¬ Chat Features
- **Real-time Streaming**: Live response streaming with WebSocket support
- **Chat History**: Persistent conversation storage
- **File Attachments**: Upload and reference files in conversations
- **Multi-session Support**: Manage multiple chat sessions

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frontend      â”‚    â”‚    Backend      â”‚    â”‚   Vector DB     â”‚
â”‚   (Next.js)     â”‚â—„â”€â”€â–ºâ”‚   (FastAPI)     â”‚â—„â”€â”€â–ºâ”‚   (Weaviate)    â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚
â”‚ â€¢ React UI      â”‚    â”‚ â€¢ RAG Engine    â”‚    â”‚ â€¢ Document      â”‚
â”‚ â€¢ Chat Interfaceâ”‚    â”‚ â€¢ PII Detection â”‚    â”‚   Embeddings    â”‚
â”‚ â€¢ File Upload   â”‚    â”‚ â€¢ Auth System   â”‚    â”‚ â€¢ Similarity    â”‚
â”‚ â€¢ Theming       â”‚    â”‚ â€¢ File Storage  â”‚    â”‚   Search        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Quick Start

### Prerequisites
- Docker & Docker Compose
- Python 3.11+
- Node.js 18+
- Azure OpenAI API access
- Weaviate instance

### 1. Clone Repository
```bash
git clone https://github.com/your-repo/ai-guardian.git
cd ai-guardian
```

### 2. Environment Setup

#### Backend Configuration
Create `backend/.env`:
```env
# Azure OpenAI Configuration
deployment_name=your-deployment-name
model_name=gpt-4
azure_endpoint=https://your-resource.openai.azure.com/
openai_api_key=your-api-key
openai_api_version=2024-02-15-preview

# Embedding Model
embedding_deployment_name=text-embedding-ada-002
embedding_model_name=text-embedding-ada-002
embedding_azure_endpoint=https://your-resource.openai.azure.com/
embedding_openai_api_key=your-embedding-api-key
embedding_openai_api_version=2024-02-15-preview

# Weaviate Configuration
WEAVIATE_URL=http://localhost:8080
WEAVIATE_API_KEY=your-weaviate-key

# Database
DATABASE_URL=postgresql://user:password@localhost:5432/ai_guardian

# MinIO (File Storage)
MINIO_ENDPOINT=localhost:9000
MINIO_ACCESS_KEY=minioadmin
MINIO_SECRET_KEY=minioadmin

# Security
SECRET_KEY=your-secret-key-here
JWT_SECRET_KEY=your-jwt-secret
```

#### Frontend Configuration
Create `frontend/.env.local`:
```env
NEXT_PUBLIC_API_URL=http://localhost:8000
NEXT_PUBLIC_APP_URL=http://localhost:3000
```

### 3. Docker Deployment
```bash
# Start all services
docker-compose up -d

# View logs
docker-compose logs -f
```

### 4. Manual Setup (Development)

#### Backend Setup
```bash
cd backend

# Install dependencies
pip install -r requirements.txt
# or with Poetry
poetry install

# Run database migrations
alembic upgrade head

# Start server
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

#### Frontend Setup
```bash
cd frontend

# Install dependencies
npm install
# or with pnpm
pnpm install

# Start development server
npm run dev
# or
pnpm dev
```

## ğŸ“š API Documentation

Once the backend is running, access the interactive API documentation:
- **Swagger UI**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc

### Key Endpoints

#### Authentication
- `POST /user/register` - User registration
- `POST /user/login` - User authentication
- `GET /user/profile` - Get user profile

#### Chat & Conversations
- `GET /api/sessions/{session_id}` - Get chat history
- `POST /api/sessions/{session_id}` - Send message to chat session

#### File Management
- `POST /file/upload` - Upload file
- `POST /file/extract` - Extract text from uploaded file

#### PII Protection
- `POST /mask/` - Mask sensitive content
- `POST /mask/unmask` - Unmask content
- `POST /mask/validate-sensitive` - Check for sensitive information

#### RAG Operations
- `POST /ai/rag/query` - Query document knowledge base
- `POST /ai/rag/update` - Update RAG content

## ğŸ”§ Configuration

### RAG Configuration
The system uses multiple specialized LLM configurations for different tasks:

- **Agent Decision**: Temperature 0.1 (deterministic)
- **Conversation**: Temperature 0.7 (creative but factual)
- **RAG Response**: Temperature 0.3 (balanced)
- **Summarization**: Temperature 0.5 (moderate creativity)

### Vector Database
- **Embedding Model**: Azure OpenAI text-embedding-ada-002
- **Vector Dimension**: 1536
- **Distance Metric**: Cosine similarity
- **Chunk Size**: 512 tokens with 50 token overlap

### PII Detection
Supported entity types:
- Names, emails, phone numbers
- Credit card numbers, SSNs
- Addresses, dates of birth
- Custom entity patterns

## ğŸ§ª Testing

```bash
# Backend tests
cd backend
pytest

# Frontend tests
cd frontend
npm test
```

## ğŸ“ Project Structure

```
ai-guardian/
â”œâ”€â”€ backend/                    # FastAPI backend
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ api/routers/       # API route handlers
â”‚   â”‚   â”œâ”€â”€ models/            # Database models
â”‚   â”‚   â”œâ”€â”€ schemas/           # Pydantic schemas
â”‚   â”‚   â”œâ”€â”€ services/          # Business logic
â”‚   â”‚   â”‚   â””â”€â”€ agents/        # AI agent implementations
â”‚   â”‚   â”œâ”€â”€ database/          # Database configuration
â”‚   â”‚   â””â”€â”€ config.py          # Application configuration
â”‚   â”œâ”€â”€ alembic/               # Database migrations
â”‚   â”œâ”€â”€ tests/                 # Test suites
â”‚   â””â”€â”€ requirements.txt       # Python dependencies
â”œâ”€â”€ frontend/                  # Next.js frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ app/              # App router pages
â”‚   â”‚   â”œâ”€â”€ components/       # Reusable components
â”‚   â”‚   â”œâ”€â”€ hooks/            # Custom React hooks
â”‚   â”‚   â”œâ”€â”€ lib/              # Utility libraries
â”‚   â”‚   â””â”€â”€ services/         # API services
â”‚   â””â”€â”€ package.json          # Node.js dependencies
â””â”€â”€ docker-compose.yml        # Container orchestration
```

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“œ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- [Presidio](https://github.com/microsoft/presidio) for PII detection
- [LangChain](https://github.com/langchain-ai/langchain) for LLM orchestration
- [Weaviate](https://weaviate.io/) for vector database
- [FastAPI](https://fastapi.tiangolo.com/) for backend framework
- [Next.js](https://nextjs.org/) for frontend framework

## ğŸ“ Support

For support, email support@aiguardian.com or join our [Discord community](https://discord.gg/aiguardian).

---

**Made with â¤ï¸ by the AI Guardian Team**
